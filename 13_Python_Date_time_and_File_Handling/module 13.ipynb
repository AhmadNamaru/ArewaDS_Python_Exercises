{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Datetime Exercises\n",
    "1. Get the current day, month, year, hour, minute and timestamp from datetime module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_day = now.day\n",
    "current_month = now.month\n",
    "current_year = now.year\n",
    "current_hour = now.hour\n",
    "current_minute = now.minute\n",
    "current_timestamp = now.timestamp()\n",
    "\n",
    "print(f\"Day: {current_day}\")\n",
    "print(f\"Month: {current_month}\")\n",
    "print(f\"Year: {current_year}\")\n",
    "print(f\"Hour: {current_hour}\")\n",
    "print(f\"Minute: {current_minute}\")\n",
    "print(f\"Timestamp: {current_timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Format the current date using this format: \"%m/%d/%Y, %H:%M:%S\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "formatted_date = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "print(formatted_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Today is 5 December, 2019. Change this time string to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_string = \"5 December, 2019\"\n",
    "time_object = datetime.strptime(time_string, \"%d %B, %Y\")\n",
    "print(time_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calculate the time difference between now and new year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime(year=2025, month=1, day=23)\n",
    "new_year = datetime(year=2026, month=1, day=1)\n",
    "\n",
    "time_left_for_newyear = new_year - today\n",
    "\n",
    "print('Time left for new year: ', time_left_for_newyear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate the time difference between 1 January 1970 and now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = datetime.now()\n",
    "nyear = datetime(year=1970, month=1, day=1)\n",
    "\n",
    "time_difference = today - nyear\n",
    "\n",
    "print(f'The Time Difference between \"{nyear}\" and \"{today}\" is : ', time_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Think, what can you use the datetime module for? Examples:\n",
    "* Time series analysis\n",
    "* To get a timestamp of any activities in an application\n",
    "* Adding posts on a blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer\n",
    "* Scheduling tasks\n",
    "* Logging events\n",
    "* Measuring execution time of code\n",
    "* Handling time zones\n",
    "* Creating countdown timers\n",
    "* Validating date and time input\n",
    "* Calculating age from birthdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Handling Exercises:\n",
    "#### Exercises: Level 1\n",
    "1. Write a function which count number of lines and number of words in a text. All the files are in the data the folder: \n",
    "\n",
    "a) Read obama_speech.txt file and count number of lines and words \n",
    "   \n",
    "b) Read michelle_obama_speech.txt file and count number of lines and words \n",
    "\n",
    "c) Read donald_speech.txt file and count number of lines and words \n",
    "\n",
    "d) Read melina_trump_speech.txt file and count number of lines and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lines_and_words(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        num_lines = len(lines)\n",
    "        num_words = sum(len(line.split()) for line in lines)\n",
    "    return num_lines, num_words\n",
    "\n",
    "# File paths\n",
    "files = [\n",
    "    'C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\obama_speech.txt',\n",
    "    'C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\michelle_obama_speech.txt',\n",
    "    'C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\donald_speech.txt',\n",
    "    'C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\melina_trump_speech.txt'\n",
    "]\n",
    "\n",
    "# Count lines and words for each file\n",
    "for file in files:\n",
    "    lines, words = count_lines_and_words(file)\n",
    "    print(f'{file}: {lines} lines, {words} words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Read the countries_data.json data file in data directory, create a function that finds the ten most spoken languages\n",
    "\n",
    "#### Your output should look like this\n",
    "print(most_spoken_languages(filename='./data/countries_data.json', 10))\n",
    "[(91, 'English'),\n",
    "(45, 'French'),\n",
    "(25, 'Arabic'),\n",
    "(24, 'Spanish'),\n",
    "(9, 'Russian'),\n",
    "(9, 'Portuguese'),\n",
    "(8, 'Dutch'),\n",
    "(7, 'German'),\n",
    "(5, 'Chinese'),\n",
    "(4, 'Swahili'),\n",
    "(4, 'Serbian')]\n",
    "\n",
    "#### Your output should look like this\n",
    "print(most_spoken_languages(filename='./data/countries_data.json', 3))\n",
    "[(91, 'English'),\n",
    "(45, 'French'),\n",
    "(25, 'Arabic')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def most_spoken_languages(filename, top_n):\n",
    "    with open(filename, 'r') as file:\n",
    "        countries_data = json.load(file)\n",
    "    \n",
    "    languages_counter = Counter()\n",
    "    \n",
    "    for country in countries_data:\n",
    "        languages_counter.update(country['languages'])\n",
    "    \n",
    "    most_common_languages = languages_counter.most_common(top_n)\n",
    "    return most_common_languages\n",
    "\n",
    "print(most_spoken_languages(filename='./data/countries_data.json', 10))\n",
    "print(most_spoken_languages(filename='./data/countries_data.json', 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Read the countries_data.json data file in data directory, create a function that creates a list of the ten most populated countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def most_populated_countries(filename, top_n):\n",
    "    with open(filename, 'r') as file:\n",
    "        countries_data = json.load(file)\n",
    "    \n",
    "    sorted_countries = sorted(countries_data, key=lambda x: x['population'], reverse=True)\n",
    "    most_populated = [{'country': country['name'], 'population': country['population']} for country in sorted_countries[:top_n]]\n",
    "    \n",
    "    return most_populated\n",
    "\n",
    "print(most_populated_countries(filename='C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\countries_data.json', 10))\n",
    "print(most_populated_countries(filename='C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\countries_data.json', 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Level 2\n",
    "4. Extract all incoming email addresses as a list from the email_exchange_big.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_email_addresses(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "    email_addresses = re.findall(email_pattern, content)\n",
    "    \n",
    "    return email_addresses\n",
    "\n",
    "email_addresses = extract_email_addresses('C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\email_exchange_big.txt')\n",
    "print(email_addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. find the most common words in the English language. Call the name of your function find_most_common_words, it will take two parameters - a string or a file and a positive integer, indicating the number of words. Your function will return an array of tuples in descending order. Check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def find_most_common_words(text_or_file, num_words):\n",
    "    if isinstance(text_or_file, str):\n",
    "        try:\n",
    "            with open(text_or_file, 'r') as file:\n",
    "                text = file.read()\n",
    "        except FileNotFoundError:\n",
    "            text = text_or_file\n",
    "    else:\n",
    "        raise ValueError(\"The first parameter should be a string representing text or a file path.\")\n",
    "    \n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    word_counts = Counter(words)\n",
    "    most_common = word_counts.most_common(num_words)\n",
    "    \n",
    "    return most_common\n",
    "\n",
    "print(find_most_common_words('C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\obama_speech.txt', 3))\n",
    "\n",
    "file_path = 'C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\obama_speech.txt'\n",
    "print(find_most_common_words(file_path, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Use the function, find_most_frequent_words to find: \n",
    "* a) The ten most frequent words used in Obama's speech \n",
    "* b) The ten most frequent words used in Michelle's speech \n",
    "* c) The ten most frequent words used in Trump's speech \n",
    "* d) The ten most frequent words used in Melina's speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) The ten most frequent words used in Obama's speech\n",
    "obama_speech_common_words = find_most_common_words('C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\obama_speech.txt', 10)\n",
    "print(\"Obama's speech:\", obama_speech_common_words)\n",
    "\n",
    "# b) The ten most frequent words used in Michelle's speech\n",
    "michelle_speech_common_words = find_most_common_words('C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\michelle_obama_speech.txt', 10)\n",
    "print(\"Michelle's speech:\", michelle_speech_common_words)\n",
    "\n",
    "# c) The ten most frequent words used in Trump's speech\n",
    "trump_speech_common_words = find_most_common_words('C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\donald_speech.txt', 10)\n",
    "print(\"Trump's speech:\", trump_speech_common_words)\n",
    "\n",
    "# d) The ten most frequent words used in Melina's speech\n",
    "melina_speech_common_words = find_most_common_words('C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\melina_trump_speech.txt', 10)\n",
    "print(\"Melina's speech:\", melina_speech_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a python application that checks similarity between two texts. It takes a file or a string as a parameter and it will evaluate the similarity of the two texts. For instance check the similarity between the transcripts of Michelle's and Melina's speech. You may need a couple of functions, function to clean the text(clean_text), function to remove support words(remove_support_words) and finally to check the similarity(check_text_similarity). List of stop words are in the data directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "def remove_support_words(text, stop_words):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def check_text_similarity(text1, text2):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([text1, text2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_sim = cosine_similarity(vectors)\n",
    "    return cosine_sim[0, 1]\n",
    "\n",
    "\n",
    "# Read the speeches\n",
    "with open('C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\michelle_obama_speech.txt', 'r') as file:\n",
    "    michelle_speech = file.read()\n",
    "\n",
    "with open('C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\melina_trump_speech.txt', 'r') as file:\n",
    "    melina_speech = file.read()\n",
    "\n",
    "# Clean and remove stop words from the speeches\n",
    "michelle_speech_cleaned = remove_support_words(clean_text(michelle_speech), stop_words)\n",
    "melina_speech_cleaned = remove_support_words(clean_text(melina_speech), stop_words)\n",
    "\n",
    "# Check similarity\n",
    "similarity = check_text_similarity(michelle_speech_cleaned, melina_speech_cleaned)\n",
    "print(f\"Similarity between Michelle's and Melina's speeches: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Find the 10 most repeated words in the romeo_and_juliet.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 10 most repeated words in the romeo_and_juliet.txt\n",
    "romeo_and_juliet_common_words = find_most_common_words('C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\romeo_and_juliet.txt', 10)\n",
    "print(\"Romeo and Juliet:\", romeo_and_juliet_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Read the hacker news csv file and find out: \n",
    "* a) Count the number of lines containing python or Python \n",
    "* b) Count the number lines containing JavaScript, javascript or Javascript \n",
    "* c) Count the number lines containing Java and not JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the hacker news CSV file\n",
    "hacker_news_df = pd.read_csv('C:\\\\Users\\\\User\\\\Desktop\\\\ArewaDS_Python_Exercises\\\\data\\\\hacker_news.csv')\n",
    "\n",
    "# a) Count the number of lines containing python or Python\n",
    "python_count = hacker_news_df['title'].str.contains('python', case=False, na=False).sum()\n",
    "print(f\"Number of lines containing 'python' or 'Python': {python_count}\")\n",
    "\n",
    "# b) Count the number lines containing JavaScript, javascript or Javascript\n",
    "javascript_count = hacker_news_df['title'].str.contains('javascript', case=False, na=False).sum()\n",
    "print(f\"Number of lines containing 'JavaScript', 'javascript' or 'Javascript': {javascript_count}\")\n",
    "\n",
    "# c) Count the number lines containing Java and not JavaScript\n",
    "java_count = hacker_news_df['title'].str.contains(r'\\bJava\\b', case=False, na=False).sum()\n",
    "java_not_javascript_count = java_count - javascript_count\n",
    "print(f\"Number of lines containing 'Java' and not 'JavaScript': {java_not_javascript_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
